{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a631eaf-e629-49cc-9fa5-2a05cf989068",
   "metadata": {},
   "source": [
    "# RAG Based Application with PDF Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16d9965-86c7-4728-b427-16f49737ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import fitz  # pymupdf\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb import PersistentClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca02c3ad-7cb2-4986-b382-e76f3ce92920",
   "metadata": {},
   "source": [
    "## Extracting the PDF Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1ac526-f3d7-4927-86df-e5afef205346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(path):\n",
    "    doc = fitz.open(path)\n",
    "    pages = []\n",
    "    for i, p in enumerate(doc):\n",
    "        text = p.get_text(\"text\")\n",
    "        pages.append((i, text))   # IMPORTANT: tuple (page_number, text)\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4aab9c-aa73-499e-995f-872274af7b7e",
   "metadata": {},
   "source": [
    "## Divide the Text into Smaller Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe261dfd-cfec-457a-b1a9-12966a32724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, overlap=200):\n",
    "    tokens = text.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        chunk = tokens[i:i+chunk_size]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "        i += chunk_size - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5ee35-5cca-48c5-acaf-89ce38644e38",
   "metadata": {},
   "source": [
    "## Processing the PDF For storing in Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976cecb8-f1ce-4da6-90ff-8f5dade02715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_pdf(pdf_path):\n",
    "    pages = extract_text_from_pdf(pdf_path)\n",
    "    all_chunks = []\n",
    "    all_ids = []\n",
    "    all_metadata = []\n",
    "\n",
    "    for page_number, page_text in pages:\n",
    "        chunks = chunk_text(page_text)\n",
    "\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            unique_id = f\"{pdf_path}_page{page_number}_chunk{idx}\"\n",
    "            metadata = {\n",
    "                \"source\": pdf_path,\n",
    "                \"page\": page_number,\n",
    "                \"chunk\": idx\n",
    "            }\n",
    "            all_chunks.append(chunk)\n",
    "            all_ids.append(unique_id)\n",
    "            all_metadata.append(metadata)\n",
    "\n",
    "    return all_chunks, all_ids, all_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acd5e1-e2e5-4641-ac88-d81df3ee2444",
   "metadata": {},
   "source": [
    "## Setting Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6997fe80-c02d-4dd8-95eb-72c565bce5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"pdf_data\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147bae9-748e-4a5c-8b7c-862a3b8142ac",
   "metadata": {},
   "source": [
    "## For adding PDFs to Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbdd9e6-442b-4163-ac5a-6ac5d6e201d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pdf_to_chroma(pdf_path):\n",
    "    chunks, ids, metadata = ingest_pdf(pdf_path)\n",
    "    embeddings = model.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=\"pdf_data\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "\n",
    "    collection.add(\n",
    "        documents=chunks,\n",
    "        metadatas=metadata,\n",
    "        ids=ids,\n",
    "        embeddings=embeddings.tolist()\n",
    "    )\n",
    "    print(f\"PDF '{pdf_path}' added successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21921f0-67a0-4733-aef1-06810cef40c1",
   "metadata": {},
   "source": [
    "## Retriving the Related data from the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3561d9a0-f864-4b59-a6df-0b33914045c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, model, collection, top_k=5, min_similarity=0.25):\n",
    "    query_emb = model.encode([query])[0]\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_emb],\n",
    "        n_results=top_k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    docs = results[\"documents\"][0]\n",
    "    metas = results[\"metadatas\"][0]\n",
    "    dists = results[\"distances\"][0]   # cosine distance\n",
    "\n",
    "    # Convert distance → similarity\n",
    "    sims = [1 - d for d in dists]\n",
    "\n",
    "    # If ALL similarities are low → return empty\n",
    "    if max(sims) < min_similarity:\n",
    "        return [], [], []\n",
    "\n",
    "    return docs, metas, sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abecd44-0521-4619-ab87-4e6c432de72b",
   "metadata": {},
   "source": [
    "## Building the Prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3799aea-2980-4e2b-bc9b-192c18cac4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(chunks, question):\n",
    "    context = \"\"\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        context += f\"\\n--- Chunk {i+1} ---\\n{chunk}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant.\n",
    "You MUST follow these rules:\n",
    "\n",
    "1. You are ONLY allowed to answer using the context.\n",
    "2. If the answer is not explicitly found in the context, you MUST reply exactly:\n",
    "   \"I don't know based on the provided documents.\"\n",
    "3. Do NOT use your own knowledge.\n",
    "4. Do NOT guess. Do NOT assume.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9261f-f656-43ee-b17d-0acb8237932e",
   "metadata": {},
   "source": [
    "## Using Ollama Local API for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8cc46d-d4b7-41f5-8209-64c31a79b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ollama(prompt):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"mistral\",\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    response = requests.post(url, json=payload, stream=True)\n",
    "    \n",
    "    output = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            data = json.loads(line)\n",
    "            output += data.get(\"response\", \"\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc7f4d7-a493-4ac4-bbb2-f43e64e71ad9",
   "metadata": {},
   "source": [
    "## Final Answer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98fb80e-8bbe-48b2-affe-29d70d5cb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    # STEP 1 — retrieve chunks using vector search\n",
    "    chunks, metadatas, ids = retrieve_relevant_chunks(\n",
    "        query=question,\n",
    "        model=model,\n",
    "        collection=collection,\n",
    "        top_k=5\n",
    "    )\n",
    "\n",
    "    if len(chunks) == 0:\n",
    "        return \"I don't know based on the provided documents.\"\n",
    "\n",
    "    # STEP 2 — build LLM prompt using retrieved chunks\n",
    "    prompt = build_prompt(chunks, question)\n",
    "\n",
    "    # STEP 3 — ask the Ollama model\n",
    "    answer = ask_ollama(prompt)\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1ea1a-b973-464c-96b7-5eee2577e6d9",
   "metadata": {},
   "source": [
    "## Adding PDFs to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34ca69b-13c5-487c-8fc2-bc9445d32eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2f666782dd465581268dfb0c768806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 'book2.pdf' added successfully!\n"
     ]
    }
   ],
   "source": [
    "add_pdf_to_chroma('book.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6238d54c-981d-4b1a-bf9d-248fc4514b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An array in Java can be created by using an array initializer as shown in Chunk 1:\n",
      "```java\n",
      "type[] var-name = {value1, value2, ...};\n",
      "```\n",
      "For example, to store the number of days in each month, the following code creates an initialized array of integers:\n",
      "```java\n",
      "int[] month_days = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31};\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = ask_question(\"How can we create an array in JAVA?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41cd19-4806-4d0d-8a3f-1c55c4d48c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
